{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bachirzerroug/Library/Caches/pypoetry/virtualenvs/transformers-implementation-xd7zxmCX-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHeadSelfAttentionQKV(nn.Module):\n",
    "    def __init__(self, k, low_dim):\n",
    "        super().__init__()\n",
    "        # Check if input is divisible by number of heads\n",
    "        self.k = k    \n",
    "        self.low_dim = low_dim \n",
    "        # 1. Define linear transformations to reduce dimensionnalit√© of input\n",
    "        # biais = False because we want only weights\n",
    "        self.to_reduce_dim = nn.Linear(k, low_dim, bias=False)\n",
    "        # 2. Define linear transformations to key, queries and values\n",
    "        # biais = False because we want only weights\n",
    "        self.to_queries = nn.Linear(low_dim, low_dim, bias=False)\n",
    "        self.to_keys    = nn.Linear(low_dim, low_dim, bias=False) \n",
    "        self.to_values  = nn.Linear(low_dim, low_dim, bias=False)\n",
    "\n",
    "    def forward(self, Q, K, V, mask):\n",
    "        # 3. Reduce dimensionnalit√© of input\n",
    "        low_dim_Q = self.to_reduce_dim(Q)\n",
    "        low_dim_K = self.to_reduce_dim(K)\n",
    "        low_dim_V = self.to_reduce_dim(V)\n",
    "\n",
    "        \n",
    "        # 4. Apply the linear transformation associated to every input to obtain the key, query and value\n",
    "        query = self.to_queries(low_dim_Q) \n",
    "        key = self.to_keys(low_dim_K)\n",
    "        value = self.to_values(low_dim_V)\n",
    "\n",
    "        # 5. Compute the raw weights w‚Ä≤ij=ùê™iTùê§j and normalize them\n",
    "        weights_raw = torch.bmm(query, key.transpose(1, 2))\n",
    "        \n",
    "        # 5.a apply mask\n",
    "        if mask is not None:\n",
    "            weights_raw = weights_raw.masked_fill_(mask.logical_not(), float(\"-1e20\"))\n",
    "\n",
    "        weights_raw_normalized = torch.div(weights_raw, torch.sqrt(torch.tensor(self.low_dim)))\n",
    "\n",
    "        # 6. We apply the Softmax function to the similarity dimension (batch dim x input dim x sim dim)\n",
    "        weights = nn.Softmax(dim=2)(weights_raw_normalized)\n",
    "\n",
    "        # 7. Multiply weights of self attention to the values\n",
    "        return torch.bmm(weights, value)\n",
    "    \n",
    "\n",
    "class MultiHeadSelfAttentionQKV(nn.Module):\n",
    "    # 8.Define a head number that is divisible from the input \n",
    "    def __init__(self, k, heads=4):\n",
    "        super().__init__()\n",
    "        # Check if input is divisible by number of heads\n",
    "        assert k % heads == 0\n",
    "\n",
    "        self.k = k\n",
    "        self.heads = heads  \n",
    "\n",
    "        # 9. Instantiate OneHeadSelfAttention multiple times to have MultiHeadSelfAttention\n",
    "        self.list_heads = []\n",
    "        for head in range(self.heads):\n",
    "            self.list_heads.append(OneHeadSelfAttentionQKV(k, k//heads))\n",
    "\n",
    "        # This will be applied after the multi-head self-attention operation.\n",
    "        self.unifyheads = nn.Linear(k, k)\n",
    "    \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        # 10. Get all heads elements \n",
    "        list_to_concat = []\n",
    "        for one_head in self.list_heads:\n",
    "            list_to_concat.append((one_head(Q, K, V, mask),))\n",
    "\n",
    "        # 11. Concatenate all the heads\n",
    "        multi_heads = sum(list_to_concat, ())        \n",
    "        concatenated = torch.cat(multi_heads, dim=2)\n",
    "\n",
    "        # 12. Linear transformation\n",
    "        return self.unifyheads(concatenated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 100, 256])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(12, 100, 256)\n",
    "mask  = torch.tril(torch.ones((100, 100)), diagonal=1).bool()\n",
    "M = MultiHeadSelfAttentionQKV(256, 4)\n",
    "M(X, X, X, mask=mask).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, vocab_size, dimension):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.word_embedding = nn.Embedding(vocab_size, dimension)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.word_embedding(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, dimension, max_seq_length=2000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "\n",
    "        positional_encoding = torch.zeros(max_seq_length, dimension)    \n",
    "        for pos in range(max_seq_length):\n",
    "            for i in range(dimension):\n",
    "                if i%2 == 0:\n",
    "                    pe = math.sin(pos / 1000**(2*i/dimension))\n",
    "                else:\n",
    "                    pe = math.cos(pos / 1000**(2*i/dimension))\n",
    "                positional_encoding[pos, i] = pe\n",
    "\n",
    "        self.register_buffer('positional_encoding', positional_encoding)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.positional_encoding[:x.size(1), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, embed_dim, factor=2):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(embed_dim, factor*embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(factor*embed_dim, embed_dim)\n",
    "        )  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.feed_forward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/encoder.png\" alt=\"drawing\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncodingBloc(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_heads, factor):\n",
    "        super(TransformerEncodingBloc, self).__init__()\n",
    "        # Mutli Head Attention with its notmalization and its dropout\n",
    "        self.attention = MultiHeadSelfAttentionQKV(embedding_dim, num_heads)\n",
    "        self.normalization_mha = nn.LayerNorm(embedding_dim)\n",
    "        self.dropout_mha = nn.Dropout(0.2)\n",
    "\n",
    "        # Feed Forward with its notmalization and its dropout\n",
    "        self.feed_forward = FeedForward(embedding_dim, factor)\n",
    "        self.normalization_ff = nn.LayerNorm(embedding_dim)\n",
    "        self.dropout_ff = nn.Dropout(0.2)\n",
    "        \n",
    "\n",
    "    def forward(self, query, key, value):\n",
    "        # Multi Head Attention\n",
    "        mha = self.attention(query, key, value)\n",
    "        mha_residuals = mha + value\n",
    "        mha_residuals_norm = self.normalization_mha(mha_residuals)\n",
    "        mha_residuals_norm_dropout = self.dropout_mha(mha_residuals_norm)\n",
    "\n",
    "        # Feed Forward\n",
    "        ff = self.feed_forward(mha_residuals_norm_dropout)\n",
    "        ff_residuals = ff + mha_residuals_norm_dropout\n",
    "        ff_residuals_norm = self.normalization_ff(ff_residuals)\n",
    "        ff_residuals_norm_dropout = self.dropout_ff(ff_residuals_norm)\n",
    "\n",
    "        return ff_residuals_norm_dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, num_heads, num_layers, factor):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = Embedding(vocab_size, embedding_dim)\n",
    "        self.positional_embedding = PositionalEmbedding(embedding_dim)\n",
    "        self.transformer_layers = nn.ModuleList([TransformerEncodingBloc(embedding_dim, num_heads, factor) for i in range(num_layers)])\n",
    "\n",
    "    def forward(self, X):\n",
    "        encoded = self.embedding(X)\n",
    "        output = self.positional_embedding(encoded)\n",
    "        for transformer_layer in self.transformer_layers:\n",
    "            output = transformer_layer(output, output, output)\n",
    "        \n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randint(low=0, high=100, size=(10, 100))\n",
    "\n",
    "encoder = Encoder(vocab_size=5000, \n",
    "                  embedding_dim=256, \n",
    "                  num_heads=4,\n",
    "                  #dropout=0.2,\n",
    "                  num_layers=5,\n",
    "                  factor=2\n",
    "                  )\n",
    "\n",
    "Y = encoder(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 21])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "batch_sentences = [\n",
    "    \"But what about second breakfast?\",\n",
    "    \"Don't think he knows about second breakfast, Pip.\",\n",
    "    \"What about elevensies?\",\n",
    "    \"In a cold and gray Chicago morning, a poor little baby child is born in the ghetto\",\n",
    "    \"I'll be there for you and the rain starts to pour\",\n",
    "    \"I like big butts and I cannot lie\",\n",
    "]\n",
    "\n",
    "encoded_input = tokenizer(batch_sentences, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "encoded_input.input_ids.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 6.7944e-01,  2.8338e-01, -3.7313e-01,  ...,  0.0000e+00,\n",
       "          -1.0727e+00, -3.1629e-01],\n",
       "         [-2.3392e+00,  5.0566e-01, -1.3224e-01,  ...,  1.1924e-02,\n",
       "          -0.0000e+00,  6.5399e-02],\n",
       "         [ 1.4677e+00, -4.3367e+00, -0.0000e+00,  ..., -8.7870e-01,\n",
       "          -5.6033e+00, -3.4865e-01],\n",
       "         ...,\n",
       "         [-6.3084e-02,  4.8442e-01, -3.2037e-01,  ...,  4.1424e-01,\n",
       "          -2.0410e-01, -0.0000e+00],\n",
       "         [ 5.8662e-01,  1.2720e-01, -0.0000e+00,  ...,  2.9111e-01,\n",
       "           2.3979e-01, -2.2068e-01],\n",
       "         [-6.1205e-02, -2.1769e-01, -0.0000e+00,  ...,  1.4815e-01,\n",
       "          -5.1326e-02, -1.4213e-02]],\n",
       "\n",
       "        [[-0.0000e+00,  3.2570e-01,  0.0000e+00,  ...,  8.2373e-02,\n",
       "          -4.1571e-02,  2.7427e-01],\n",
       "         [-1.7784e+00,  1.1714e+00,  7.8142e-01,  ..., -4.0248e-01,\n",
       "          -2.3180e-01,  8.7191e-03],\n",
       "         [-3.0134e-01,  6.6591e-02,  1.7326e+00,  ...,  3.5466e-01,\n",
       "          -0.0000e+00, -7.6266e-01],\n",
       "         ...,\n",
       "         [ 3.7141e-01, -0.0000e+00, -0.0000e+00,  ..., -9.7708e-01,\n",
       "           7.5023e-02, -2.1047e-01],\n",
       "         [ 6.2847e-01,  8.4333e-02, -0.0000e+00,  ...,  1.7118e-01,\n",
       "          -2.2377e-01, -5.0678e-02],\n",
       "         [ 0.0000e+00, -4.0028e-02,  6.0311e-01,  ...,  0.0000e+00,\n",
       "          -1.0417e-01,  6.2403e-01]],\n",
       "\n",
       "        [[-3.0877e-01, -2.9449e-01,  5.5141e-01,  ...,  0.0000e+00,\n",
       "          -0.0000e+00, -1.7695e-01],\n",
       "         [ 3.7432e-01,  4.1009e-01,  2.7156e-01,  ..., -5.7016e-01,\n",
       "          -8.0062e-01,  1.1711e+00],\n",
       "         [ 0.0000e+00, -1.2122e-01,  1.6937e-01,  ..., -2.0185e-01,\n",
       "          -6.9851e-01, -1.3628e-01],\n",
       "         ...,\n",
       "         [ 2.5496e-01, -1.4974e+00, -3.4361e-01,  ..., -3.0362e-02,\n",
       "           0.0000e+00,  5.0832e-01],\n",
       "         [-3.0078e-01,  2.4243e-01, -7.0987e-01,  ..., -8.3288e-02,\n",
       "          -0.0000e+00, -0.0000e+00],\n",
       "         [-0.0000e+00,  8.6365e-02,  0.0000e+00,  ..., -7.2704e-01,\n",
       "          -0.0000e+00,  2.9494e-01]],\n",
       "\n",
       "        [[ 0.0000e+00,  3.3153e-01,  6.1756e-02,  ..., -9.9741e-01,\n",
       "          -5.6595e-01, -3.0146e-01],\n",
       "         [ 6.9801e-01,  3.7784e-01,  6.4372e-01,  ...,  0.0000e+00,\n",
       "          -0.0000e+00,  2.6387e+00],\n",
       "         [-1.5227e+00,  0.0000e+00, -2.3171e+00,  ..., -4.4877e-02,\n",
       "          -5.8759e-01, -1.6657e-01],\n",
       "         ...,\n",
       "         [ 1.7192e-01,  3.1290e-01,  2.9604e-01,  ...,  5.7890e-01,\n",
       "           1.2021e+00, -2.3389e-02],\n",
       "         [ 4.6242e-02,  1.6565e-03, -3.0297e-01,  ...,  0.0000e+00,\n",
       "          -0.0000e+00, -7.2254e-01],\n",
       "         [-1.7352e-01,  2.4592e-02,  1.5947e-01,  ..., -7.0896e-01,\n",
       "          -4.4661e-01, -2.3423e-02]],\n",
       "\n",
       "        [[ 5.3049e-01,  8.4853e-01, -5.1844e+00,  ...,  2.5670e-01,\n",
       "          -0.0000e+00,  2.7982e-01],\n",
       "         [ 1.8408e+00, -0.0000e+00, -8.3434e-02,  ..., -0.0000e+00,\n",
       "           3.6781e-01,  1.3448e-01],\n",
       "         [-3.7605e-01, -2.8666e-01,  1.2767e-01,  ..., -1.9511e+00,\n",
       "          -8.7717e-02, -1.3174e-01],\n",
       "         ...,\n",
       "         [ 3.5591e-01,  0.0000e+00, -3.3985e-01,  ...,  2.1311e-01,\n",
       "           5.8671e+00, -1.8279e+00],\n",
       "         [-4.1769e-01,  1.5400e+00,  4.4923e-03,  ...,  6.0757e-01,\n",
       "          -1.5616e-02, -6.3327e-01],\n",
       "         [-2.5248e-01, -6.3811e-02, -3.6825e-01,  ..., -1.1800e+00,\n",
       "          -2.8743e-01, -5.2808e-01]],\n",
       "\n",
       "        [[-0.0000e+00,  6.2652e-02,  7.5714e-02,  ...,  0.0000e+00,\n",
       "          -0.0000e+00,  0.0000e+00],\n",
       "         [ 7.5931e-01,  0.0000e+00, -1.4512e-01,  ..., -3.0975e-01,\n",
       "          -5.7823e-01, -0.0000e+00],\n",
       "         [ 6.4719e+00,  0.0000e+00, -0.0000e+00,  ..., -4.8221e-02,\n",
       "          -0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00, -7.6488e-01,  0.0000e+00,  ..., -9.9685e-01,\n",
       "           3.0855e-01,  3.4217e-01],\n",
       "         [ 1.5000e+00, -7.5515e-01,  1.7347e+00,  ..., -1.0647e-01,\n",
       "           3.6495e-01,  0.0000e+00],\n",
       "         [-1.0090e-01,  8.2171e-02,  0.0000e+00,  ...,  6.9750e-02,\n",
       "           6.5023e-01, -0.0000e+00]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder(vocab_size=tokenizer.vocab_size, \n",
    "                  embedding_dim=256, \n",
    "                  num_heads=4,\n",
    "                  num_layers=5,\n",
    "                  factor=2\n",
    "                  )\n",
    "\n",
    "encoder(encoded_input.input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/decoder.png\" alt=\"drawing\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecodingBloc(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_heads, factor):\n",
    "        super(TransformerDecodingBloc, self).__init__()\n",
    "        # Mutli Head Self Attention with its notmalization and its dropout\n",
    "        self.self_attention = MultiHeadSelfAttentionQKV(embedding_dim, num_heads)\n",
    "        self.normalization_mhsa = nn.LayerNorm(embedding_dim)\n",
    "        self.dropout_mhsa = nn.Dropout(0.2)\n",
    "\n",
    "        # Mutli Head cross Attention with its notmalization and its dropout\n",
    "        self.cross_attention = MultiHeadSelfAttentionQKV(embedding_dim, num_heads)\n",
    "        self.normalization_mhca = nn.LayerNorm(embedding_dim)\n",
    "        self.dropout_mhca = nn.Dropout(0.2)\n",
    "\n",
    "        # Feed Forward with its notmalization and its dropout\n",
    "        self.feed_forward = FeedForward(embedding_dim, factor)\n",
    "        self.normalization_ff = nn.LayerNorm(embedding_dim)\n",
    "        self.dropout_ff = nn.Dropout(0.2)\n",
    "        \n",
    "\n",
    "    def forward(self, x, encoder, mask):\n",
    "        # Mutli Head Self Attention\n",
    "        mhsa = self.self_attention(x, x, x, mask)\n",
    "        mhsa_residuals = mhsa + x\n",
    "        mhsa_residuals_norm = self.normalization_mhsa(mhsa_residuals)\n",
    "        mhsa_residuals_norm_dropout = self.dropout_mhsa(mhsa_residuals_norm)\n",
    "\n",
    "        # Mutli Head Cross Attention\n",
    "        query = mhsa_residuals_norm_dropout\n",
    "        mhca = self.cross_attention(query, encoder, encoder) # Query belongs to self attention and Key and Value from encoder\n",
    "        mhca_residuals = mhca + query\n",
    "        mhca_residuals_norm = self.normalization_mhca(mhca_residuals)\n",
    "        mhca_residuals_norm_dropout = self.dropout_mhca(mhca_residuals_norm)\n",
    "\n",
    "         # Feed Forward with its notmalization and its dropout\n",
    "        ff = self.feed_forward(mhca_residuals_norm_dropout)\n",
    "        ff_residuals = ff + mhca_residuals_norm_dropout\n",
    "        ff_residuals_norm = self.normalization_ff(ff_residuals)\n",
    "        ff_residuals_norm_dropout = self.dropout_ff(ff_residuals_norm)\n",
    "\n",
    "        return ff_residuals_norm_dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, num_heads, num_layers, factor=1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = Embedding(vocab_size, embedding_dim)\n",
    "        self.positional_embedding = PositionalEmbedding(embedding_dim)\n",
    "        self.transformer_layers = nn.ModuleList([TransformerDecodingBloc(embedding_dim, num_heads, factor) for i in range(num_layers)])\n",
    "        self.linear_out = nn.Linear(embedding_dim, vocab_size)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "\n",
    "    def forward(self, x, encoder_out, mask=None):\n",
    "        encoded = self.embedding(x)\n",
    "        output = self.positional_embedding(encoded)\n",
    "        output = self.dropout(output)\n",
    "        for transformer_layer in self.transformer_layers:\n",
    "            output = transformer_layer(output, encoder_out, mask)\n",
    "            \n",
    "        output = self.linear_out(output)\n",
    "        \n",
    "        return nn.Softmax(dim=2)(output)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, input_vocab_size, output_vocab_size, embedding_dim, num_heads, num_layers, factor=2):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(input_vocab_size, embedding_dim, num_heads, num_layers, factor)\n",
    "        self.decoder = Decoder(output_vocab_size, embedding_dim, num_heads, num_layers, factor)\n",
    "\n",
    "    def get_mask_output(self, output):\n",
    "        _, output_len = output.size()\n",
    "        return torch.tril(torch.ones((output_len, output_len)), diagonal=1).bool()\n",
    "    \n",
    "\n",
    "    def forward(self, input, output):\n",
    "        encoder = self.encoder(input) \n",
    "        mask = self.get_mask_output(output)\n",
    "        return self.decoder(output, encoder, mask=mask) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 21])\n",
      "torch.Size([6, 36])\n"
     ]
    }
   ],
   "source": [
    "batch_input = [\n",
    "    \"But what about second breakfast?\",\n",
    "    \"Don't think he knows about second breakfast, Pip.\",\n",
    "    \"What about elevensies?\",\n",
    "    \"In a cold and gray Chicago morning, a poor little baby child is born in the ghetto\",\n",
    "    \"I'll be there for you and the rain starts to pour\",\n",
    "    \"I like big butts and I cannot lie\",\n",
    "]\n",
    "\n",
    "batch_output = [\n",
    "    \"Pourquoi pas\",\n",
    "    \"Je ne pense pas\",\n",
    "    \"Je ne sais pas\",\n",
    "    \"J'ai pass√© la bague √† Chikita, deux mois apr√®s je l'ai d√©j√† quitt√©\",\n",
    "    \"H et Kaamelot sont les s√©ries fran√ßaises les plus marrantes\",\n",
    "    \"j'entends des bruits sur mon t√©l√©phone sans fil\",\n",
    "]\n",
    "\n",
    "tokenizer_input = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "tokenizer_output = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "encoded_input = tokenizer_input(batch_input, padding=True, return_tensors=\"pt\")\n",
    "print(encoded_input.input_ids.size())\n",
    "\n",
    "encoded_output = tokenizer_output(batch_output, padding=True, return_tensors=\"pt\")\n",
    "print(encoded_output.input_ids.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28996"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_output.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(input_vocab_size=tokenizer_input.vocab_size,\n",
    "                          output_vocab_size=tokenizer_output.vocab_size,\n",
    "                          embedding_dim=256, \n",
    "                          num_heads=4, \n",
    "                          num_layers=5, \n",
    "                          factor=2\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = transformer(encoded_input.input_ids, encoded_output.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 36])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_output.input_ids.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 36, 28996])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Tensor.size>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input.input_ids.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = Encoder(vocab_size=tokenizer_input.vocab_size, \n",
    "            embedding_dim=256, \n",
    "            num_heads=8, \n",
    "            num_layers=3, \n",
    "            factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = A(encoded_input.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 21, 256])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.size()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use transformerencoder for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "emails_raw = pd.read_csv('../data/spam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URGENT! You have won a 1 week FREE membership in our ¬£100,000 Prize Jackpot! Txt the word: CLAIM to No: 81010 T&C www.dbuk.net LCCLTD POBOX 4403LDNW1A7RW18\n",
      "Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "Do you know what Mallika Sherawat did yesterday? Find out now @  &lt;URL&gt;\n",
      "K..u also dont msg or reply to his msg..\n"
     ]
    }
   ],
   "source": [
    "# Look at some examples\n",
    "print(emails_raw['Message'].iloc[12])\n",
    "print(emails_raw['Message'].iloc[0])\n",
    "print(emails_raw['Message'].iloc[55])\n",
    "print(emails_raw['Message'].iloc[700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the dataset: (5572, 2)\n",
      "Number unique classes 2\n",
      "Proportions of classes: \n",
      "            Message\n",
      "Category          \n",
      "ham       0.865937\n",
      "spam      0.134063\n",
      "Number of distinct emails: 5157\n"
     ]
    }
   ],
   "source": [
    "# Get some basic stats\n",
    "print(f'shape of the dataset: {emails_raw.shape}')\n",
    "\n",
    "# Number of classes\n",
    "nb_classes = emails_raw['Category'].nunique()\n",
    "print(f'Number unique classes {nb_classes}')\n",
    "\n",
    "# Proportion of classes\n",
    "proportions_classes = emails_raw.groupby('Category').count()/len(emails_raw)\n",
    "print(f'Proportions of classes: \\n {proportions_classes}')\n",
    "# Number of distinct emails\n",
    "print(f'Number of distinct emails: {emails_raw.Message.nunique()}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is unbalanced.  \n",
    "However the positive class is big enough to avoid (under/over) sampling or even classweights.\n",
    "\n",
    "We have 5157 unique emails and 5572 raws in the dataset. Let's check if they have the same class and can be deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_count = emails_raw.groupby('Message').count()\n",
    "message_count.columns = ['nb_messages']\n",
    "message_count = message_count[message_count['nb_messages']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_messages</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Message</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mila, age23, blonde, new in UK. I look sex with UK guys. if u like fun with me. Text MTALK to 69866.18 . 30pp/txt 1st 5free. ¬£1.50 increments. Help08718728876</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ok lor.</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ok thanx...</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ok then i will come to ur home after half an hour</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRIVATE! Your 2004 Account Statement for 07742676969 shows 786 unredeemed Bonus Points. To claim call 08719180248 Identifier Code: 45239 Expires</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Say this slowly.? GOD,I LOVE YOU &amp;amp; I NEED YOU,CLEAN MY HEART WITH YOUR BLOOD.Send this to Ten special people &amp;amp; u c miracle tomorrow, do it,pls,pls do it...</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7 wonders in My WORLD 7th You 6th Ur style 5th Ur smile 4th Ur Personality 3rd Ur Nature 2nd Ur SMS and 1st \"Ur Lovely Friendship\"... good morning dear</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ok...</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I cant pick the phone right now. Pls send a message</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sorry, I'll call later</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>289 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    nb_messages\n",
       "Message                                                        \n",
       "Mila, age23, blonde, new in UK. I look sex with...            2\n",
       "Ok lor.                                                       2\n",
       "Ok thanx...                                                   2\n",
       "Ok then i will come to ur home after half an hour             2\n",
       "PRIVATE! Your 2004 Account Statement for 077426...            2\n",
       "...                                                         ...\n",
       "Say this slowly.? GOD,I LOVE YOU &amp; I NEED Y...            4\n",
       "7 wonders in My WORLD 7th You 6th Ur style 5th ...            4\n",
       "Ok...                                                        10\n",
       "I cant pick the phone right now. Pls send a mes...           12\n",
       "Sorry, I'll call later                                       30\n",
       "\n",
       "[289 rows x 1 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_count.sort_values(by='nb_messages')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that repeated emails are\n",
    "1. emails with basic answers like 'OK'\n",
    "2. emails we can send automatically when someone call us \"Sorry, I'll call later\"\n",
    "3. emails considered as chain \"Send this to Ten special people\"\n",
    "4. spams received by multiple accounts  \n",
    "...  \n",
    "\n",
    "Let's check if they belong to the same class at least"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_all_msg_same_class(message):\n",
    "    list_similar_emails = emails_raw[emails_raw['Message'] == message]['Category']\n",
    "    class_email = list_similar_emails.iloc[0]\n",
    "    return list_similar_emails.tolist() == [class_email]*len(list_similar_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for message in message_count.index:\n",
    "    if not check_all_msg_same_class(message):\n",
    "        print('There are similar emails that have at least 2 different classes')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distinct messages have the same class in the dataset.  \n",
    "Which means that there is not incoherence in the dataset information carried by these emails.  \n",
    "The decision concerning these emails depend on how the dataset is built.\n",
    "1. If the dataset is a sample of real emails received by a representative group of persons, then we can keep them. Indeed by keeping them we give them more weight which is logical as they appear multiple times.\n",
    "2. If these emails are selectionned, it doesn't make sense to give more weight to specific emails, except if there is a idea behind.  \n",
    "\n",
    "As we don't have information, we suppose that these emails are a sample of real emails"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform dataframe to a pytorch Dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "5567    1\n",
       "5568    0\n",
       "5569    0\n",
       "5570    0\n",
       "5571    0\n",
       "Name: category_binary, Length: 5572, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_raw['category_binary'] = [0 if msg == 'ham' else 1 for msg in emails_raw['Category']]\n",
    "emails_raw['category_binary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_input = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "encoded_input = tokenizer_input(emails_raw['Message'].tolist(), padding=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5572, 293])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input.input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_val, x_test, y_train_val, y_test = train_test_split(encoded_input.input_ids, \n",
    "                                                            torch.tensor(emails_raw['category_binary'], \n",
    "                                                                         dtype=torch.float32), \n",
    "                                                            train_size=0.8, \n",
    "                                                            shuffle=True,\n",
    "                                                            stratify=torch.tensor(emails_raw['category_binary'], \n",
    "                                                                     dtype=torch.float32),\n",
    "                                                            random_state=12)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val,\n",
    "                                                  y_train_val,\n",
    "                                                  train_size=0.8, \n",
    "                                                  shuffle=True,\n",
    "                                                  stratify=y_train_val,\n",
    "                                                  random_state=56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of x_train: 3565 and y_train: 3565\n",
      "Shapes of x_val: 892 and y_val: 892\n",
      "Shapes of x_test: 1115 and y_test: 1115\n",
      "proportion of spam in train: 0.13408134877681732, in validation: 0.13452914357185364, and in test: 0.13363228738307953\n"
     ]
    }
   ],
   "source": [
    "print(f'Shapes of x_train: {len(x_train)} and y_train: {len(y_train)}')\n",
    "print(f'Shapes of x_val: {len(x_val)} and y_val: {len(y_val)}')\n",
    "print(f'Shapes of x_test: {len(x_test)} and y_test: {len(y_test)}')\n",
    "print(f'proportion of spam in train: {y_train.sum()/len(y_train)}, in validation: {y_val.sum()/len(y_val)}, and in test: {y_test.sum()/len(y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.length = self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx],self.y[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = dataset(x_train, y_train)\n",
    "val_set = dataset(x_val, y_val)\n",
    "test_set = dataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataLoader\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0, verbose=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after the last time the validation loss improved.\n",
    "                            Default: 5\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                           Default: 0\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
    "                            Default: False\n",
    "            path (str): Path to save the model checkpoint when the validation loss improves.\n",
    "                        Default: 'checkpoint.pt'\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            val_loss (float): Validation loss to monitor.\n",
    "            model (nn.Module): PyTorch model to save when the validation loss improves.\n",
    "        \"\"\"\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_loss\n",
    "        elif val_loss < self.best_score - self.delta:\n",
    "            self.best_score = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f'EarlyStopping Counter: {self.counter} out of {self.patience}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamClassifier(nn.Module):\n",
    "    def __init__(self, \n",
    "                 embedding_dim,\n",
    "                 vocab_size=tokenizer_input.vocab_size, \n",
    "                 num_heads=4, \n",
    "                 num_layers=3, \n",
    "                 factor=2,\n",
    "                 latent_1=64):\n",
    "        super().__init__()\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.encoder = Encoder(\n",
    "            vocab_size=vocab_size, \n",
    "            embedding_dim=embedding_dim, \n",
    "            num_heads=num_heads, \n",
    "            num_layers=num_layers, \n",
    "            factor=factor\n",
    "        )\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, latent_1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(latent_1, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder = self.encoder(x)\n",
    "        encoder_reshaped = encoder.mean(dim=1)\n",
    "        out = self.linear(encoder_reshaped)\n",
    "        return self.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y.unsqueeze(1))\n",
    "\n",
    "        # Backpropagation\n",
    "        # Backpropagate the prediction loss with a call to loss.backward(). \n",
    "        # PyTorch deposits the gradients of the loss w.r.t. each parameter.\n",
    "        loss.backward()\n",
    "        # Once we have our gradients, we call optimizer.step() to adjust the parameters \n",
    "        # by the gradients collected in the backward pass.\n",
    "        optimizer.step()\n",
    "        # Call optimizer.zero_grad() to reset the gradients of model parameters. \n",
    "        # Gradients by default add up; to prevent double-counting, we explicitly zero them at each iteration.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, pr_aucs = 0, []\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            # Perform predict\n",
    "            pred = model(X)\n",
    "            # Compute the the prediction error (loss) and convert it to numpy\n",
    "            test_loss += loss_fn(pred, y.unsqueeze(1)).item()\n",
    "            # Sum of correct predictions\n",
    "            pr_aucs.append(average_precision_score(y.numpy(), pred.numpy()))\n",
    "            y_true += y.numpy().tolist()\n",
    "            y_pred += pred.numpy().tolist()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    pr_auc = np.mean(pr_aucs)\n",
    "    print(f\"Test Error: Avg loss: {test_loss:>8f} and pr auc: {pr_auc} \\n\")\n",
    "    return test_loss, y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper parameters\n",
    "learning_rate = 0.001\n",
    "epochs = 10\n",
    "embedding_dim = 256\n",
    "# Model , Optimizer, Loss\n",
    "model = SpamClassifier(embedding_dim=embedding_dim)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.625748  [   64/ 3565]\n",
      "loss: 0.397953  [  704/ 3565]\n",
      "loss: 0.435655  [ 1344/ 3565]\n",
      "loss: 0.398657  [ 1984/ 3565]\n",
      "loss: 0.295726  [ 2624/ 3565]\n",
      "loss: 0.293966  [ 3264/ 3565]\n",
      "Test Error: Avg loss: 0.264266 and pr auc: 0.626284843384567 \n",
      "\n",
      "EarlyStopping Counter: 0 out of 3\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.283406  [   64/ 3565]\n",
      "loss: 0.240218  [  704/ 3565]\n",
      "loss: 0.385211  [ 1344/ 3565]\n",
      "loss: 0.332299  [ 1984/ 3565]\n",
      "loss: 0.218402  [ 2624/ 3565]\n",
      "loss: 0.210103  [ 3264/ 3565]\n",
      "Test Error: Avg loss: 0.229136 and pr auc: 0.7138833195194734 \n",
      "\n",
      "EarlyStopping Counter: 0 out of 3\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.203358  [   64/ 3565]\n",
      "loss: 0.176023  [  704/ 3565]\n",
      "loss: 0.265041  [ 1344/ 3565]\n",
      "loss: 0.189610  [ 1984/ 3565]\n",
      "loss: 0.195706  [ 2624/ 3565]\n",
      "loss: 0.140894  [ 3264/ 3565]\n",
      "Test Error: Avg loss: 0.178549 and pr auc: 0.8375465164676716 \n",
      "\n",
      "EarlyStopping Counter: 0 out of 3\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.161442  [   64/ 3565]\n",
      "loss: 0.107301  [  704/ 3565]\n",
      "loss: 0.233217  [ 1344/ 3565]\n",
      "loss: 0.072308  [ 1984/ 3565]\n",
      "loss: 0.087755  [ 2624/ 3565]\n",
      "loss: 0.073072  [ 3264/ 3565]\n",
      "Test Error: Avg loss: 0.267812 and pr auc: 0.9595617486124886 \n",
      "\n",
      "EarlyStopping Counter: 1 out of 3\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.131180  [   64/ 3565]\n",
      "loss: 0.035049  [  704/ 3565]\n",
      "loss: 0.095834  [ 1344/ 3565]\n",
      "loss: 0.068091  [ 1984/ 3565]\n",
      "loss: 0.080903  [ 2624/ 3565]\n",
      "loss: 0.022650  [ 3264/ 3565]\n",
      "Test Error: Avg loss: 0.097825 and pr auc: 0.969115340444122 \n",
      "\n",
      "EarlyStopping Counter: 0 out of 3\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.018336  [   64/ 3565]\n",
      "loss: 0.036892  [  704/ 3565]\n",
      "loss: 0.074066  [ 1344/ 3565]\n",
      "loss: 0.025916  [ 1984/ 3565]\n",
      "loss: 0.023209  [ 2624/ 3565]\n",
      "loss: 0.007488  [ 3264/ 3565]\n",
      "Test Error: Avg loss: 0.092337 and pr auc: 0.9782147903834323 \n",
      "\n",
      "EarlyStopping Counter: 0 out of 3\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.005623  [   64/ 3565]\n",
      "loss: 0.039142  [  704/ 3565]\n",
      "loss: 0.053939  [ 1344/ 3565]\n",
      "loss: 0.025976  [ 1984/ 3565]\n",
      "loss: 0.014972  [ 2624/ 3565]\n",
      "loss: 0.010973  [ 3264/ 3565]\n",
      "Test Error: Avg loss: 0.100648 and pr auc: 0.9789746334299805 \n",
      "\n",
      "EarlyStopping Counter: 1 out of 3\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.003028  [   64/ 3565]\n",
      "loss: 0.003539  [  704/ 3565]\n",
      "loss: 0.006090  [ 1344/ 3565]\n",
      "loss: 0.015497  [ 1984/ 3565]\n",
      "loss: 0.006574  [ 2624/ 3565]\n",
      "loss: 0.002725  [ 3264/ 3565]\n",
      "Test Error: Avg loss: 0.118593 and pr auc: 0.9791923832976683 \n",
      "\n",
      "EarlyStopping Counter: 2 out of 3\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.000973  [   64/ 3565]\n",
      "loss: 0.004719  [  704/ 3565]\n",
      "loss: 0.022827  [ 1344/ 3565]\n",
      "loss: 0.006136  [ 1984/ 3565]\n",
      "loss: 0.001244  [ 2624/ 3565]\n",
      "loss: 0.000566  [ 3264/ 3565]\n",
      "Test Error: Avg loss: 0.094389 and pr auc: 0.9826062051007909 \n",
      "\n",
      "EarlyStopping Counter: 3 out of 3\n",
      "Early stopping\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "early_stopping = EarlyStopping(patience=3, verbose=True)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "    val_loss, _, _ = eval(val_loader, model, loss_fn)\n",
    "    \n",
    "    # Check for early stopping\n",
    "    early_stopping(val_loss, model)\n",
    "    \n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: Avg loss: 0.067687 and pr auc: 0.9868463642233011 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss, y_true, y_pred = eval(test_loader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute precision and recall\n",
    "precision, recall, _ = precision_recall_curve(y_true, y_pred)\n",
    "average_precision = average_precision_score(y_true, y_pred)\n",
    "\n",
    "# Plot precision-recall curve using Seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.lineplot(x=precision, y=recall, label=f'Precision-Recall Curve (AP = {average_precision:.2f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_pred = pd.DataFrame({'y_true': y_true, 'y_pred': [x[0] for x in y_pred]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1115 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      y_true    y_pred\n",
       "0        0.0  0.000021\n",
       "1        0.0  0.000146\n",
       "2        0.0  0.000018\n",
       "3        1.0  0.999184\n",
       "4        1.0  0.999231\n",
       "...      ...       ...\n",
       "1110     1.0  0.999254\n",
       "1111     0.0  0.000025\n",
       "1112     0.0  0.000049\n",
       "1113     0.0  0.000021\n",
       "1114     0.0  0.000019\n",
       "\n",
       "[1115 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up the figure with two subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n",
    "\n",
    "# Plot the histograms side by side using Seaborn\n",
    "sns.histplot(y_true_pred[y_true_pred['y_true'] == 1]['y_pred'], bins=30, ax=axes[0], color='blue', label='Spam')\n",
    "sns.histplot(y_true_pred[y_true_pred['y_true'] == 0]['y_pred'], bins=30, ax=axes[1], color='orange', label='Non Spam')\n",
    "\n",
    "# Add legend\n",
    "axes[0].legend()\n",
    "axes[1].legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1336322869955157"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_true_pred[y_true_pred['y_pred'] > 0.5])/len(y_true_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers-implementation-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
